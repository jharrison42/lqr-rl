{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import gym\n",
    "from collections import deque\n",
    "import random\n",
    "import time\n",
    "import yaml\n",
    "from klqr import *\n",
    "from train_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config.yml','r') as ymlfile:\n",
    "    config = yaml.load(ymlfile)\n",
    "    \n",
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession(config=tf.ConfigProto(log_device_placement=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "z shape: (?, 6)\n",
      "********** Iteration 1 ************\n",
      "\tLast Episode Reward: 0\n",
      "********** Iteration 2 ************\n",
      "\tLast Episode Reward: -1028\n",
      "********** Iteration 3 ************\n",
      "\tLast Episode Reward: -1028\n",
      "********** Iteration 4 ************\n",
      "\tLast Episode Reward: -1128\n",
      "********** Iteration 5 ************\n",
      "\tLast Episode Reward: -1128\n",
      "********** Iteration 6 ************\n",
      "\tLast Episode Reward: -894\n",
      "********** Iteration 7 ************\n",
      "\tLast Episode Reward: -894\n",
      "********** Iteration 8 ************\n",
      "\tLast Episode Reward: -890\n",
      "********** Iteration 9 ************\n",
      "\tLast Episode Reward: -890\n",
      "********** Iteration 10 ************\n",
      "\tLast Episode Reward: -976\n",
      "********** Iteration 11 ************\n",
      "\tLast Episode Reward: -976\n",
      "********** Iteration 12 ************\n",
      "\tLast Episode Reward: -864\n",
      "********** Iteration 13 ************\n",
      "\tLast Episode Reward: -864\n",
      "********** Iteration 14 ************\n",
      "\tLast Episode Reward: -945\n",
      "********** Iteration 15 ************\n",
      "\tLast Episode Reward: -945\n",
      "********** Iteration 16 ************\n",
      "\tLast Episode Reward: -993\n",
      "********** Iteration 17 ************\n",
      "\tLast Episode Reward: -993\n",
      "********** Iteration 18 ************\n",
      "\tLast Episode Reward: -966\n",
      "********** Iteration 19 ************\n",
      "\tLast Episode Reward: -966\n",
      "********** Iteration 20 ************\n",
      "\tLast Episode Reward: -1082\n",
      "********** Iteration 21 ************\n",
      "\tLast Episode Reward: -1082\n",
      "********** Iteration 22 ************\n",
      "\tLast Episode Reward: -930\n",
      "********** Iteration 23 ************\n",
      "\tLast Episode Reward: -930\n",
      "********** Iteration 24 ************\n",
      "\tLast Episode Reward: -766\n",
      "********** Iteration 25 ************\n",
      "\tLast Episode Reward: -766\n",
      "********** Iteration 26 ************\n",
      "\tLast Episode Reward: -919\n",
      "********** Iteration 27 ************\n",
      "\tLast Episode Reward: -919\n",
      "********** Iteration 28 ************\n",
      "\tLast Episode Reward: -793\n",
      "********** Iteration 29 ************\n",
      "\tLast Episode Reward: -793\n",
      "********** Iteration 30 ************\n",
      "\tLast Episode Reward: -863\n",
      "********** Iteration 31 ************\n",
      "\tLast Episode Reward: -863\n",
      "********** Iteration 32 ************\n",
      "\tLast Episode Reward: -974\n",
      "********** Iteration 33 ************\n",
      "\tLast Episode Reward: -974\n",
      "********** Iteration 34 ************\n",
      "\tLast Episode Reward: -1043\n",
      "********** Iteration 35 ************\n",
      "\tLast Episode Reward: -1043\n",
      "********** Iteration 36 ************\n",
      "\tLast Episode Reward: -971\n",
      "********** Iteration 37 ************\n",
      "\tLast Episode Reward: -971\n",
      "********** Iteration 38 ************\n",
      "\tLast Episode Reward: -876\n",
      "********** Iteration 39 ************\n",
      "\tLast Episode Reward: -876\n",
      "********** Iteration 40 ************\n",
      "\tLast Episode Reward: -942\n",
      "********** Iteration 41 ************\n",
      "\tLast Episode Reward: -942\n",
      "********** Iteration 42 ************\n",
      "\tLast Episode Reward: -911\n",
      "********** Iteration 43 ************\n",
      "\tLast Episode Reward: -911\n",
      "********** Iteration 44 ************\n",
      "\tLast Episode Reward: -912\n",
      "********** Iteration 45 ************\n",
      "\tLast Episode Reward: -912\n",
      "********** Iteration 46 ************\n",
      "\tLast Episode Reward: -1045\n",
      "********** Iteration 47 ************\n",
      "\tLast Episode Reward: -1045\n",
      "********** Iteration 48 ************\n",
      "\tLast Episode Reward: -808\n",
      "********** Iteration 49 ************\n",
      "\tLast Episode Reward: -808\n",
      "********** Iteration 50 ************\n",
      "\tLast Episode Reward: -961\n",
      "********** Iteration 51 ************\n",
      "\tLast Episode Reward: -961\n",
      "********** Iteration 52 ************\n",
      "\tLast Episode Reward: -1201\n",
      "********** Iteration 53 ************\n",
      "\tLast Episode Reward: -1201\n",
      "********** Iteration 54 ************\n",
      "\tLast Episode Reward: -886\n",
      "********** Iteration 55 ************\n",
      "\tLast Episode Reward: -886\n",
      "********** Iteration 56 ************\n",
      "\tLast Episode Reward: -1065\n",
      "********** Iteration 57 ************\n",
      "\tLast Episode Reward: -1065\n",
      "********** Iteration 58 ************\n",
      "\tLast Episode Reward: -964\n",
      "********** Iteration 59 ************\n",
      "\tLast Episode Reward: -964\n",
      "********** Iteration 60 ************\n",
      "\tLast Episode Reward: -1046\n",
      "********** Iteration 61 ************\n",
      "\tLast Episode Reward: -1046\n",
      "********** Iteration 62 ************\n",
      "\tLast Episode Reward: -953\n",
      "********** Iteration 63 ************\n",
      "\tLast Episode Reward: -953\n",
      "********** Iteration 64 ************\n",
      "\tLast Episode Reward: -819\n",
      "********** Iteration 65 ************\n",
      "\tLast Episode Reward: -819\n",
      "********** Iteration 66 ************\n",
      "\tLast Episode Reward: -1073\n",
      "********** Iteration 67 ************\n",
      "\tLast Episode Reward: -1073\n",
      "********** Iteration 68 ************\n",
      "\tLast Episode Reward: -905\n",
      "********** Iteration 69 ************\n",
      "\tLast Episode Reward: -905\n",
      "********** Iteration 70 ************\n",
      "\tLast Episode Reward: -908\n",
      "********** Iteration 71 ************\n",
      "\tLast Episode Reward: -908\n",
      "********** Iteration 72 ************\n",
      "\tLast Episode Reward: -853\n",
      "********** Iteration 73 ************\n",
      "\tLast Episode Reward: -853\n",
      "********** Iteration 74 ************\n",
      "\tLast Episode Reward: -854\n",
      "********** Iteration 75 ************\n",
      "\tLast Episode Reward: -854\n",
      "********** Iteration 76 ************\n",
      "\tLast Episode Reward: -864\n",
      "********** Iteration 77 ************\n",
      "\tLast Episode Reward: -864\n",
      "********** Iteration 78 ************\n",
      "\tLast Episode Reward: -795\n",
      "********** Iteration 79 ************\n",
      "\tLast Episode Reward: -795\n",
      "********** Iteration 80 ************\n",
      "\tLast Episode Reward: -998\n",
      "********** Iteration 81 ************\n",
      "\tLast Episode Reward: -998\n",
      "********** Iteration 82 ************\n",
      "\tLast Episode Reward: -891\n",
      "********** Iteration 83 ************\n",
      "\tLast Episode Reward: -891\n",
      "********** Iteration 84 ************\n",
      "\tLast Episode Reward: -853\n",
      "********** Iteration 85 ************\n",
      "\tLast Episode Reward: -853\n",
      "********** Iteration 86 ************\n",
      "\tLast Episode Reward: -867\n",
      "********** Iteration 87 ************\n",
      "\tLast Episode Reward: -867\n",
      "********** Iteration 88 ************\n",
      "\tLast Episode Reward: -905\n",
      "********** Iteration 89 ************\n",
      "\tLast Episode Reward: -905\n",
      "********** Iteration 90 ************\n",
      "\tLast Episode Reward: -877\n",
      "********** Iteration 91 ************\n",
      "\tLast Episode Reward: -877\n",
      "********** Iteration 92 ************\n",
      "\tLast Episode Reward: -780\n",
      "********** Iteration 93 ************\n",
      "\tLast Episode Reward: -780\n",
      "********** Iteration 94 ************\n",
      "\tLast Episode Reward: -812\n",
      "********** Iteration 95 ************\n",
      "\tLast Episode Reward: -812\n",
      "********** Iteration 96 ************\n",
      "\tLast Episode Reward: -763\n",
      "********** Iteration 97 ************\n",
      "\tLast Episode Reward: -763\n",
      "********** Iteration 98 ************\n",
      "\tLast Episode Reward: -1050\n",
      "********** Iteration 99 ************\n",
      "\tLast Episode Reward: -1050\n",
      "********** Iteration 100 ************\n",
      "[[  0.42351565   0.10943143  -0.05351136  -0.06192248  -0.22051641\n",
      "    0.02978889]\n",
      " [  0.10943143  21.600113   -13.955868    -5.188177   -12.694375\n",
      "   18.568487  ]\n",
      " [ -0.05351136 -13.955868     9.89661      3.722605     7.433118\n",
      "  -12.142946  ]\n",
      " [ -0.06192248  -5.188177     3.722605    14.241435    -5.2698913\n",
      "   -4.064229  ]\n",
      " [ -0.22051641 -12.694375     7.433118    -5.2698913   15.214268\n",
      "  -11.037952  ]\n",
      " [  0.02978889  18.568487   -12.142946    -4.064229   -11.037952\n",
      "   17.352787  ]]\n",
      "\tLast Episode Reward: -757\n",
      "********** Iteration 101 ************\n",
      "\tLast Episode Reward: -757\n",
      "********** Iteration 102 ************\n",
      "\tLast Episode Reward: -1530\n",
      "********** Iteration 103 ************\n",
      "\tLast Episode Reward: -1530\n",
      "********** Iteration 104 ************\n",
      "\tLast Episode Reward: -1464\n",
      "********** Iteration 105 ************\n",
      "\tLast Episode Reward: -1464\n",
      "********** Iteration 106 ************\n",
      "\tLast Episode Reward: -1526\n",
      "********** Iteration 107 ************\n",
      "\tLast Episode Reward: -1526\n",
      "********** Iteration 108 ************\n",
      "\tLast Episode Reward: -1449\n",
      "********** Iteration 109 ************\n",
      "\tLast Episode Reward: -1449\n",
      "********** Iteration 110 ************\n",
      "\tLast Episode Reward: -1169\n",
      "********** Iteration 111 ************\n",
      "\tLast Episode Reward: -1169\n",
      "********** Iteration 112 ************\n",
      "\tLast Episode Reward: -1473\n",
      "********** Iteration 113 ************\n",
      "\tLast Episode Reward: -1473\n",
      "********** Iteration 114 ************\n",
      "\tLast Episode Reward: -1398\n",
      "********** Iteration 115 ************\n",
      "\tLast Episode Reward: -1398\n",
      "********** Iteration 116 ************\n",
      "\tLast Episode Reward: -1527\n",
      "********** Iteration 117 ************\n",
      "\tLast Episode Reward: -1527\n",
      "********** Iteration 118 ************\n",
      "\tLast Episode Reward: -1389\n",
      "********** Iteration 119 ************\n",
      "\tLast Episode Reward: -1389\n",
      "********** Iteration 120 ************\n",
      "\tLast Episode Reward: -1453\n",
      "********** Iteration 121 ************\n",
      "\tLast Episode Reward: -1453\n",
      "********** Iteration 122 ************\n",
      "\tLast Episode Reward: -733\n",
      "********** Iteration 123 ************\n",
      "\tLast Episode Reward: -733\n",
      "********** Iteration 124 ************\n",
      "\tLast Episode Reward: -1224\n",
      "********** Iteration 125 ************\n",
      "\tLast Episode Reward: -1224\n",
      "********** Iteration 126 ************\n",
      "\tLast Episode Reward: -1290\n",
      "********** Iteration 127 ************\n",
      "\tLast Episode Reward: -1290\n",
      "********** Iteration 128 ************\n",
      "\tLast Episode Reward: -954\n",
      "********** Iteration 129 ************\n",
      "\tLast Episode Reward: -954\n",
      "********** Iteration 130 ************\n",
      "\tLast Episode Reward: -1381\n",
      "********** Iteration 131 ************\n",
      "\tLast Episode Reward: -1381\n",
      "********** Iteration 132 ************\n",
      "\tLast Episode Reward: -1089\n",
      "********** Iteration 133 ************\n",
      "\tLast Episode Reward: -1089\n",
      "********** Iteration 134 ************\n",
      "\tLast Episode Reward: -1473\n",
      "********** Iteration 135 ************\n",
      "\tLast Episode Reward: -1473\n",
      "********** Iteration 136 ************\n",
      "\tLast Episode Reward: -1221\n",
      "********** Iteration 137 ************\n",
      "\tLast Episode Reward: -1221\n",
      "********** Iteration 138 ************\n",
      "\tLast Episode Reward: -1347\n",
      "********** Iteration 139 ************\n",
      "\tLast Episode Reward: -1347\n",
      "********** Iteration 140 ************\n",
      "\tLast Episode Reward: -1463\n",
      "********** Iteration 141 ************\n",
      "\tLast Episode Reward: -1463\n",
      "********** Iteration 142 ************\n",
      "\tLast Episode Reward: -1455\n",
      "********** Iteration 143 ************\n",
      "\tLast Episode Reward: -1455\n",
      "********** Iteration 144 ************\n",
      "\tLast Episode Reward: -1226\n",
      "********** Iteration 145 ************\n",
      "\tLast Episode Reward: -1226\n",
      "********** Iteration 146 ************\n",
      "\tLast Episode Reward: -1397\n",
      "********** Iteration 147 ************\n",
      "\tLast Episode Reward: -1397\n",
      "********** Iteration 148 ************\n",
      "\tLast Episode Reward: -1325\n",
      "********** Iteration 149 ************\n",
      "\tLast Episode Reward: -1325\n",
      "********** Iteration 150 ************\n",
      "\tLast Episode Reward: -1450\n",
      "********** Iteration 151 ************\n",
      "\tLast Episode Reward: -1450\n",
      "********** Iteration 152 ************\n",
      "\tLast Episode Reward: -1283\n",
      "********** Iteration 153 ************\n",
      "\tLast Episode Reward: -1283\n",
      "********** Iteration 154 ************\n",
      "\tLast Episode Reward: -1234\n",
      "********** Iteration 155 ************\n",
      "\tLast Episode Reward: -1234\n",
      "********** Iteration 156 ************\n",
      "\tLast Episode Reward: -1317\n",
      "********** Iteration 157 ************\n",
      "\tLast Episode Reward: -1317\n",
      "********** Iteration 158 ************\n",
      "\tLast Episode Reward: -1373\n",
      "********** Iteration 159 ************\n",
      "\tLast Episode Reward: -1373\n",
      "********** Iteration 160 ************\n",
      "\tLast Episode Reward: -1289\n",
      "********** Iteration 161 ************\n",
      "\tLast Episode Reward: -1289\n",
      "********** Iteration 162 ************\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-3e759955276b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0magent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mklqr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrain_agent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/asl/lqr-rl/train_utils.py\u001b[0m in \u001b[0;36mtrain_agent\u001b[0;34m(agent, env, max_timesteps, max_episodes, max_iters, max_seconds, n_transitions_between_updates, n_optim_steps_per_update, n_iters_per_p_update)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;31m# gather experience\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0mtimesteps_so_far\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepisodes_so_far\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_cum_rew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexp_gen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;31m# optimize the model from collected data:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/asl/lqr-rl/train_utils.py\u001b[0m in \u001b[0;36mexperience_generator\u001b[0;34m(agent, env, N)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mn_steps\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0msp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mcum_rew\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/asl/lqr-rl/klqr.py\u001b[0m in \u001b[0;36mpi\u001b[0;34m(self, x, explore)\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicy_action\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mexplore\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1104\u001b[0m             \u001b[0mfeed_handles\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubfeed_val\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1105\u001b[0m           \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1106\u001b[0;31m             \u001b[0mnp_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfeed_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubfeed_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m           if (not is_tensor_handle_feed and\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m     \"\"\"\n\u001b[0;32m--> 492\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "env = gym.make('Pendulum-v0')\n",
    "agent = klqr(config,sess)\n",
    "agent.build_model()\n",
    "train_agent(agent,env,max_timesteps=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = sess.run(agent.A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.   -0.    0.    0.   -0.08 -0.  ]\n",
      " [ 0.    0.4  -0.06  0.   -0.06  0.19]\n",
      " [ 0.    0.    0.59  0.   -0.01 -0.51]\n",
      " [-0.    0.    0.    0.68 -0.27  0.13]\n",
      " [-0.   -0.   -0.08 -0.24  0.78 -0.  ]\n",
      " [ 0.    0.04  0.   -0.02 -0.    0.95]]\n"
     ]
    }
   ],
   "source": [
    "print(np.round(A*100)/100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.00648174],\n",
       "       [ 0.00433212],\n",
       "       [-0.02874016],\n",
       "       [ 0.00784383],\n",
       "       [-0.01057139],\n",
       "       [ 0.00829484]], dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(agent.B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.44878745,  0.10372268, -0.04940924, -0.02321559, -0.28664175,\n",
       "         0.02329656],\n",
       "       [ 0.10372268,  1.0297765 , -0.8721553 ,  0.34143567,  0.12583704,\n",
       "         0.56099135],\n",
       "       [-0.04940924, -0.8721553 ,  1.1417718 , -0.73204386, -0.17271739,\n",
       "        -0.44206622],\n",
       "       [-0.02321559,  0.34143567, -0.73204386,  1.1944157 , -0.37650794,\n",
       "         0.46224195],\n",
       "       [-0.28664175,  0.12583703, -0.17271736, -0.3765079 ,  1.0999533 ,\n",
       "         0.23865563],\n",
       "       [ 0.02329657,  0.56099135, -0.44206622,  0.46224198,  0.23865563,\n",
       "         0.9965708 ]], dtype=float32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(agent.Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
