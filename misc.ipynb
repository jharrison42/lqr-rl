{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import gym\n",
    "from collections import deque\n",
    "import random\n",
    "import time\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO:\n",
    "# add gradient clipping?\n",
    "\n",
    "# TO TEST:\n",
    "# enforcing norm constraint on P\n",
    "# how to do exploration\n",
    "# whether this works at all?\n",
    "\n",
    "# carries out mat*v on all v in batch_v\n",
    "# mat = [n, m], batch_v = [batch_size, m], returns [batch_size, n]\n",
    "def batch_matmul(mat, batch_v):\n",
    "    return tf.transpose(tf.matmul(mat,tf.transpose(batch_v)))\n",
    "\n",
    "def summarize_matrix(name, matrix):\n",
    "    with tf.name_scope(name):\n",
    "        eigvals, _ = tf.linalg.eigh(matrix)\n",
    "        tf.summary.scalar('max_eig', tf.reduce_max(eigvals))\n",
    "        tf.summary.scalar('min_eig', tf.reduce_min(eigvals))\n",
    "        tf.summary.scalar('mean_eig', tf.reduce_mean(eigvals))\n",
    "\n",
    "class klqr:\n",
    "    # not currently doing value updates at varying rates\n",
    "    # not currently doing double Q learning (what would this look like?)\n",
    "    \n",
    "    def __init__(self,config,sess):\n",
    "        self.sess = sess\n",
    "        \n",
    "        self.x_dim = config['x_dim']\n",
    "        self.z_dim = config['z_dim']\n",
    "        self.a_dim = config['a_dim']\n",
    "        self.lr = config['lr']\n",
    "        self.horizon = config['horizon']\n",
    "        self.gamma = config['discount_rate']\n",
    "\n",
    "        \n",
    "        ou_theta = config['ou_theta']\n",
    "        ou_sigma = config['ou_sigma']\n",
    "        self.config = config\n",
    "        \n",
    "        # Ornstein-Uhlenbeck noise for exploration -- code from Yuke Zhu\n",
    "        self.noise_var = tf.Variable(tf.zeros([self.a_dim,1]))\n",
    "        noise_random = tf.random_normal([self.a_dim,1], stddev=ou_sigma)\n",
    "        self.noise = self.noise_var.assign_sub((ou_theta) * self.noise_var - noise_random)\n",
    "\n",
    "        self.max_riccati_updates = config['max_riccati_updates']\n",
    "        self.train_batch_size = config['train_batch_size']\n",
    "        self.replay_buffer = ReplayBuffer(buffer_size=config['replay_buffer_size'])\n",
    "        \n",
    "        self.dynamics_weight = 1.0\n",
    "        self.cost_weight = 1.0\n",
    "        self.td_weight = 0.0\n",
    "        \n",
    "        self.experience_count = 0\n",
    "        \n",
    "        self.updates_so_far = 0\n",
    "        \n",
    "    def build_model(self):        \n",
    "\n",
    "        with tf.variable_scope('model',reuse=tf.AUTO_REUSE):\n",
    "            \n",
    "            self.x_ = tf.placeholder(tf.float32,shape=[None, self.x_dim])\n",
    "            self.xp_ = tf.placeholder(tf.float32,shape=[None, self.x_dim])\n",
    "            self.a_ = tf.placeholder(tf.float32,shape=[None, self.a_dim])\n",
    "            self.r_ = tf.placeholder(tf.float32,shape=[None])\n",
    "            \n",
    "            self.z = self.encoder(self.x_)\n",
    "            self.zp = self.encoder(self.xp_)\n",
    "\n",
    "            print('z shape:', self.z.get_shape())\n",
    "\n",
    "            #init R\n",
    "\n",
    "            self.R_asym = tf.get_variable('R_asym',shape=[self.a_dim,self.a_dim])\n",
    "    #         self.R_asym = tf.Variable(np.random.rand(self.a_dim,self.a_dim) - 0.5)\n",
    "\n",
    "            # working with Ra.T Ra so that inner product is norm(Rx) and not norm(R.T x)\n",
    "            self.R = tf.matmul(tf.linalg.transpose(self.R_asym),self.R_asym)\n",
    "\n",
    "            #init Q -- shape: z_dim * z_dim\n",
    "            self.Q_asym = tf.get_variable('Q_asym',shape=[self.z_dim,self.z_dim])\n",
    "            self.Q = tf.matmul(tf.linalg.transpose(self.Q_asym),self.Q_asym)\n",
    "\n",
    "            #init P -- shape: z_dim * z_dim\n",
    "            self.P = tf.get_variable('P',shape=[self.z_dim,self.z_dim],trainable=False,initializer=tf.initializers.identity)\n",
    "            self.P_asym = tf.linalg.transpose(tf.cholesky(self.P))\n",
    "\n",
    "            #init B -- shape: z_dim * u_dim\n",
    "            self.B = tf.get_variable('B',shape=[self.z_dim,self.a_dim])\n",
    "    #         self.B = tf.Variable(np.random.rand(self.z_dim,self.u_dim) - 0.5)\n",
    "\n",
    "            #init A -- shape: z_dim * z_dim\n",
    "            self.A = tf.get_variable('A',shape=[self.z_dim,self.z_dim])\n",
    "    #         self.A = tf.Variable(np.random.rand(self.z_dim,self.z_dim) - 0.5)\n",
    "\n",
    "            #define K -- shape: u_dim * z_dim\n",
    "            #term1 = tf.matrix_inverse(self.R + tf.matmul(tf.matmul(tf.transpose(self.B),self.Q),self.B))\n",
    "            term1 = tf.matrix_inverse(self.R + tf.linalg.transpose(self.B) @ self.P @ self.B)\n",
    "            term2 = tf.linalg.transpose(self.B) @ self.P @ self.A\n",
    "            self.K = -term1 @ term2\n",
    "            self.policy_action = batch_matmul(self.K, self.z) # tf.transpose(tf.matmul(self.K,tf.transpose(self.z)))\n",
    "            \n",
    "            #make reward negative to convert to cost\n",
    "            self.bootstrapped_value = -self.r_ + self.gamma*tf.square(tf.norm(batch_matmul(self.P_asym, self.zp), axis=1))\n",
    "\n",
    "            action_cost = tf.square(tf.norm(batch_matmul(self.R_asym, self.a_), axis=1))#can simplify this by taking norm on other axis\n",
    "            state_cost = tf.square(tf.norm(batch_matmul(self.Q_asym, self.z), axis=1)) \n",
    "            self.PABK = self.P_asym @ ( self.A + self.B @ self.K )\n",
    "            Vzp = tf.square(tf.norm(batch_matmul(self.PABK, self.zp), axis=1))\n",
    "            self.Qsa = action_cost + state_cost + Vzp\n",
    "            \n",
    "            # predict next state\n",
    "            self.zp_pred = batch_matmul(self.A, self.z) + batch_matmul(self.B, self.a_)\n",
    "            \n",
    "            # predict observed reward\n",
    "            self.r_pred = - action_cost - state_cost\n",
    "            print(self.r_pred.get_shape())\n",
    "\n",
    "            self.td_loss = tf.reduce_mean(tf.square(self.bootstrapped_value - self.Qsa))\n",
    "            self.dynamics_loss = tf.reduce_mean(tf.square(self.zp - self.zp_pred))\n",
    "            self.cost_pred_loss = tf.reduce_mean(tf.square(self.r_pred - self.r_))\n",
    "            \n",
    "            \n",
    "            self.loss = self.td_weight*self.td_loss + self.dynamics_weight*self.dynamics_loss + self.cost_weight*self.cost_pred_loss\n",
    "            global_step = tf.Variable(0, trainable=False, name='global_step')\n",
    "            optimizer = tf.train.AdamOptimizer(self.lr)\n",
    "            self.train_op = optimizer.minimize(self.loss, global_step=global_step)\n",
    "            \n",
    "            # utilities for doing riccati recursion\n",
    "            self.reset_P_op = self.P.assign(self.Q)\n",
    "            self.riccati_update_op = self.P.assign(self.riccati_recursion_step())\n",
    "            \n",
    "            # record summaries\n",
    "            tf.summary.scalar('dynamics_loss', self.dynamics_loss)\n",
    "            tf.summary.scalar('cost_pred_loss', self.cost_pred_loss)\n",
    "            tf.summary.scalar('td_loss', self.td_loss)\n",
    "            summarize_matrix('A', self.A)\n",
    "#             summarize_matrix('B', self.B)\n",
    "            summarize_matrix('Q', self.Q)\n",
    "            summarize_matrix('R', self.R)\n",
    "            summarize_matrix('P', self.P)\n",
    "            \n",
    "            self.merged = tf.summary.merge_all()\n",
    "            self.train_writer = tf.summary.FileWriter('summaries')\n",
    "            \n",
    "            self.sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    \n",
    "    def update_model(self):        \n",
    "        #this function is mostly taken from Yuke's code\n",
    "        if self.replay_buffer.count() < self.train_batch_size:\n",
    "            return\n",
    "        \n",
    "        batch           = self.replay_buffer.getBatch(self.train_batch_size)\n",
    "        \n",
    "        states          = np.zeros((self.train_batch_size, self.x_dim))\n",
    "        rewards         = np.zeros((self.train_batch_size))\n",
    "        actions         = np.zeros((self.train_batch_size, self.a_dim))\n",
    "        next_states     = np.zeros((self.train_batch_size, self.x_dim))\n",
    "\n",
    "        for k, (s0, a, r, s1, done) in enumerate(batch):\n",
    "            #currently throwing away done states; should fix this\n",
    "            states[k] = s0\n",
    "            rewards[k] = r\n",
    "            actions[k] = a\n",
    "            next_states[k] = s1\n",
    "            # check terminal state\n",
    "#             if not done:\n",
    "#                 next_states[k] = s1\n",
    "#                 next_state_mask[k] = 1\n",
    "\n",
    "        summary, _ = self.sess.run([self.merged, self.train_op],\n",
    "        {\n",
    "        self.x_:  states,\n",
    "        self.xp_: next_states,\n",
    "        self.a_:  actions,\n",
    "        self.r_:  rewards\n",
    "        })\n",
    "    \n",
    "        self.train_writer.add_summary(summary, self.updates_so_far)\n",
    "        self.updates_so_far += 1\n",
    "    \n",
    "        #possibly update target via Riccati recursion? or do standard target separation? \n",
    "    \n",
    "    def riccati_recursion_step(self):\n",
    "#         ABK = self.A + self.B @ self.K\n",
    "#         APA = tf.transpose(ABK) @ self.P @ ABK \n",
    "#         return self.Q + tf.transpose(self.K) @ self.R @ self.K + self.gamma*APA\n",
    "        return self.Q + tf.transpose(self.A) @ self.P @ self.A - tf.transpose(self.A) @ self.P @ self.B @ tf.matrix_inverse(self.R + tf.transpose(self.B) @ self.P @ self.B ) @ tf.transpose(self.P @ self.B) @ self.A\n",
    "    \n",
    "    def update_P(self):\n",
    "#         print('updating P')\n",
    "#         reset_q_op = \n",
    "#         self.P = tf.identity(self.Q)\n",
    "#         for k in range(self.max_riccati_updates):\n",
    "#             #do Riccati backup in tensorflow oh god why\n",
    "#             ABK = self.A + tf.matmul(self.B,self.K)\n",
    "#             APA = tf.matmul(tf.matmul(tf.transpose(ABK),self.P),ABK) #\n",
    "#             self.P = self.Q + tf.matmul(tf.matmul(tf.transpose(self.K),self.R),self.K) + self.gamma*APA\n",
    "        \n",
    "#         self.P_asym = tf.transpose(tf.cholesky(self.P))\n",
    "        sess.run(self.reset_P_op)\n",
    "        for k in range(self.max_riccati_updates):\n",
    "            sess.run(self.riccati_update_op)\n",
    "        \n",
    "        print('Q:',sess.run(self.Q))\n",
    "        print('R:',sess.run(self.R))\n",
    "        print('A:',sess.run(self.A))\n",
    "        print('B:',sess.run(self.B))\n",
    "        print('P:',sess.run(self.P))\n",
    "            #TODO add a termination criterion for norm of Riccati update difference?\n",
    "    \n",
    "    def pi(self,x,explore=True):\n",
    "        self.experience_count += 1\n",
    "        x = np.reshape(x,(1,self.x_dim))\n",
    "        a,w = self.sess.run([self.policy_action,self.noise], {self.x_: x})\n",
    "        \n",
    "        a = a + w.T if explore else a\n",
    "        return a.tolist()[0]\n",
    "        \n",
    "    def store_experience(self,s,a,r,sp,done):\n",
    "        # currently storing experience for every iteration\n",
    "        self.replay_buffer.add(s, a, r, sp, done)\n",
    "    \n",
    "    def encoder(self,x,name=\"encoder\",batch_norm=False):\n",
    "#         layer_sizes = self.config['encoder_layers']\n",
    "#         with tf.variable_scope(name,reuse=tf.AUTO_REUSE):\n",
    "#             inp = x\n",
    "#             for units in layer_sizes: \n",
    "#                 inp = tf.layers.dense(inputs=inp, units=units,activation=tf.nn.relu)\n",
    "\n",
    "#             z = tf.layers.dense(inputs=inp, units=self.z_dim,activation=None)\n",
    "\n",
    "#         if batch_norm:\n",
    "#             z = tf.layers.batch_normalization(z)\n",
    "\n",
    "        return x #z\n",
    "\n",
    "class ReplayBuffer:\n",
    "    # taken from Yuke Zhu's Q learning implementation\n",
    "    \n",
    "    def __init__(self, buffer_size):\n",
    "\n",
    "        self.buffer_size = buffer_size\n",
    "        self.num_experiences = 0\n",
    "        self.buffer = deque()\n",
    "\n",
    "    def getBatch(self, batch_size):\n",
    "        # random draw N\n",
    "        return random.sample(self.buffer, batch_size)\n",
    "\n",
    "    def size(self):\n",
    "        return self.buffer_size\n",
    "\n",
    "    def add(self, state, action, reward, next_action, done):\n",
    "        new_experience = (state, action, reward, next_action, done)\n",
    "        if self.num_experiences < self.buffer_size:\n",
    "          self.buffer.append(new_experience)\n",
    "          self.num_experiences += 1\n",
    "        else:\n",
    "          self.buffer.popleft()\n",
    "          self.buffer.append(new_experience)\n",
    "\n",
    "    def count(self):\n",
    "        # if buffer is full, return buffer size\n",
    "        # otherwise, return experience counter\n",
    "        return self.num_experiences\n",
    "\n",
    "    def erase(self):\n",
    "        self.buffer = deque()\n",
    "        self.num_experiences = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulates the agent acting in env, yielding every N steps\n",
    "# (decouples episode reseting mechanics from the training alg)\n",
    "def experience_generator(agent, env, N):\n",
    "    s = env.reset()\n",
    "    n_steps = 0\n",
    "    n_eps = 0\n",
    "    last_cum_rew = 0\n",
    "    cum_rew = 0\n",
    "    while True:\n",
    "        n_steps += 1\n",
    "        a = agent.pi(s)\n",
    "        print('s:',s)\n",
    "        sp, r, done,_ = env.step(a)\n",
    "        cum_rew += r\n",
    "        if done:\n",
    "            n_eps += 1\n",
    "            last_cum_rew = cum_rew\n",
    "            cum_rew = 0\n",
    "            s = env.reset()\n",
    "        else:\n",
    "            agent.store_experience(s, a, r, sp, done)\n",
    "            s = sp\n",
    "\n",
    "        if n_steps % N == 0:\n",
    "            yield (n_steps, n_eps, last_cum_rew)\n",
    "\n",
    "\n",
    "\n",
    "def train_agent(agent, env,\n",
    "                max_timesteps=0, max_episodes=0, max_iters=0, max_seconds=0, # time constraint\n",
    "                n_transitions_between_updates=100,\n",
    "                n_optim_steps_per_update=100,\n",
    "                n_iters_per_p_update=1,\n",
    "                ):\n",
    "\n",
    "    # run an episode, and feed data to model\n",
    "    episodes_so_far = 0\n",
    "    timesteps_so_far = 0\n",
    "    iters_so_far = 0\n",
    "    tstart = time.time()\n",
    "\n",
    "    assert sum([max_iters>0, max_timesteps>0, max_episodes>0, max_seconds>0])==1, \"Only one time constraint permitted\"\n",
    "\n",
    "    exp_gen = experience_generator(agent, env, n_transitions_between_updates)\n",
    "\n",
    "    while True:\n",
    "        iters_so_far += 1\n",
    "        if max_timesteps and timesteps_so_far >= max_timesteps:\n",
    "            break\n",
    "        elif max_episodes and episodes_so_far >= max_episodes:\n",
    "            break\n",
    "        elif max_iters and iters_so_far >= max_iters:\n",
    "            break\n",
    "        elif max_seconds and time.time() - tstart >= max_seconds:\n",
    "            break\n",
    "\n",
    "        print(\"********** Iteration %i ************\"%iters_so_far)\n",
    "\n",
    "        # gather experience\n",
    "        timesteps_so_far, episodes_so_far, last_cum_rew = exp_gen.__next__()\n",
    "\n",
    "        # optimize the model from collected data:\n",
    "        for i in range(n_optim_steps_per_update):\n",
    "            agent.update_model()\n",
    "\n",
    "        if iters_so_far % n_iters_per_p_update == 0:\n",
    "            agent.update_P()\n",
    "\n",
    "        print(\"\\tLast Episode Reward: %d\"%last_cum_rew)\n",
    "        # add other logging stuff here\n",
    "        # add saving checkpoints here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/james/Dropbox/stanford/research/current/koopman-lqr/klqr_env/lib/python3.5/site-packages/tensorflow/python/client/session.py:1711: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    }
   ],
   "source": [
    "with open('config.yml','r') as ymlfile:\n",
    "    config = yaml.load(ymlfile)\n",
    "    \n",
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession(config=tf.ConfigProto(log_device_placement=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z shape: (?, 3)\n",
      "(?,)\n",
      "********** Iteration 1 ************\n",
      "s: [1.6992663128385295, -1.6860551689642693, -1.8588843079185695]\n",
      "s: [1.9023328584428794, -1.0402942785997566, -1.3194429385429673]\n",
      "s: [1.7987009461029553, -0.44738817418507837, -0.8518707088068507]\n",
      "s: [1.4364776297116668, -0.3630877095333159, -0.920322548723233]\n",
      "s: [1.2045400581810144, -0.2657068283532201, -0.8084310248198936]\n",
      "s: [1.000171697963533, -0.12896833496276328, -0.6953615827199394]\n",
      "s: [0.8051359538913856, -0.12276974583807841, -0.5767017780312107]\n",
      "s: [0.7862555556726052, 0.08617628913070167, 0.031739051367438376]\n",
      "s: [0.6814584745179795, 0.13329917604561092, 0.8351727104830494]\n",
      "s: [0.47427802253131957, 0.2798497587166043, 1.6995325159507844]\n",
      "s: [0.3944079459875197, 0.6413795964429495, 2.290597060295639]\n",
      "s: [0.11482799065115878, 1.0943774688445642, 2.443272846914705]\n",
      "s: [-0.15842176780924355, 1.3683870044012512, 2.4760446259831403]\n",
      "s: [-0.4846013006121427, 1.5913319297467448, 2.4851417356612986]\n",
      "s: [-1.1292660431186619, 1.6586295399661946, 2.3555447288168603]\n",
      "s: [-1.8910218979290945, 1.6364077650418893, 1.8158330051908131]\n",
      "s: [-2.5147795624852476, 1.1542536014851439, 1.3360814665685037]\n",
      "s: [-3.4077694185035443, 0.7251000494311404, 0.8367896689111434]\n",
      "s: [-3.6309464100404845, -0.038663463638611395, 0.4695970234691276]\n",
      "s: [-3.778334145595166, -0.7230778609215367, 0.03201255124145913]\n",
      "s: [-3.7546947295629605, -1.6839547911352521, -0.7686746284074768]\n",
      "s: [-3.8271948099067994, -2.5510825291002566, -1.2312562178052706]\n",
      "s: [-3.759722822759567, -2.7988444621444977, -1.3684839606656074]\n",
      "s: [-3.517635946940185, -2.8504005100236984, -1.301002248965745]\n",
      "s: [-3.217996312791606, -2.728173682511126, -1.602886513033445]\n",
      "s: [-2.7516182502751443, -2.6636806326380746, -1.5409815041535242]\n",
      "s: [-2.3138741922338184, -2.4516594353624743, -1.4110829868461467]\n",
      "s: [-2.0756240516904336, -2.439039132049861, -1.2351558891368213]\n",
      "s: [-2.1353816194749733, -2.3942854177010946, -1.3409855125587669]\n",
      "s: [-2.2265174438217654, -2.443655767837147, -1.2049197161872356]\n",
      "s: [-2.407798277076243, -2.4749544842976756, -1.2808836458677155]\n",
      "s: [-2.8014406394751297, -2.428143770155023, -0.7292281931138835]\n",
      "s: [-2.8702373822637552, -2.5711367077066214, -0.6053856099384443]\n",
      "s: [-3.010841413702085, -2.4869059332434134, -0.7730024574550032]\n",
      "s: [-3.256818032633232, -2.2293246376400284, -0.9790773946857871]\n",
      "s: [-3.7388859233556158, -2.2284227013072027, -0.7437105136084003]\n",
      "s: [-4.01896884981978, -2.3844038916806856, -0.6345115295833645]\n",
      "s: [-4.3063571465502, -2.3171801505322516, -0.8399442875047571]\n",
      "s: [-4.80882667893795, -2.157570313082145, -0.8714314523387394]\n",
      "s: [-5.220188620705828, -1.8851712115171457, -1.0926303463347309]\n",
      "s: [-5.334116738900037, -1.762018136576276, -1.3500941141859981]\n",
      "s: [-5.434641773177941, -1.7416713493477243, -1.6064585728491605]\n",
      "s: [-5.093631794630657, -2.00495249193912, -2.1921254035258277]\n",
      "s: [-4.744679712355037, -2.381958638547422, -2.5373989565778343]\n",
      "s: [-4.566675231962437, -2.5143110049446844, -2.6846706269730944]\n",
      "s: [-4.635857900430326, -2.5654208350447036, -2.710442025278735]\n",
      "s: [-4.757768355163111, -2.8232133899978553, -2.929021323825263]\n",
      "s: [-4.593870530019772, -3.014015527907027, -2.9805156802407176]\n",
      "s: [-3.9407272088855745, -3.3940929284052874, -2.759373790209865]\n",
      "s: [-3.306809640576084, -3.5592276933254308, -2.5408546092077793]\n",
      "s: [-2.8615826970108875, -3.5092195978494676, -2.519929301615355]\n",
      "s: [-2.7544296931345746, -3.4405775582464138, -2.419405119430537]\n",
      "s: [-2.4979450424178027, -3.385305615773606, -2.398360762169435]\n",
      "s: [-2.060692378053507, -3.4820184254767517, -2.427897695238475]\n",
      "s: [-1.843349488464955, -3.4886200730562305, -2.5373586069410616]\n",
      "s: [-1.750846623248525, -3.319150374640895, -2.657241622554683]\n",
      "s: [-1.609208887061662, -3.5240641982404415, -2.8741472681340134]\n",
      "s: [-1.9945249361971946, -3.8013275511991367, -2.6761911217346475]\n",
      "s: [-2.0757072171576656, -4.04291996012613, -2.886623988967259]\n",
      "s: [-2.080544620899351, -3.896783543451421, -3.1392732184941456]\n",
      "s: [-1.9908349912173282, -3.8433121060684794, -2.9998775972727123]\n",
      "s: [-1.8464189284646713, -3.642084837843524, -2.631000666767961]\n",
      "s: [-1.5410370272761056, -3.240086209050509, -2.2537112340369436]\n",
      "s: [-1.264697206243663, -2.9422031688743058, -1.8061667121165614]\n",
      "s: [-1.2635131022517334, -2.794268191210502, -1.6751956489172204]\n",
      "s: [-1.5245573223598257, -2.629118300153621, -1.7156141402979568]\n",
      "s: [-1.6000586932160679, -2.582841885532649, -1.7431382619595546]\n",
      "s: [-1.491016067651179, -2.33667111624865, -2.1060377133489365]\n",
      "s: [-1.1125464269981955, -2.1843207743353856, -2.2409477440089485]\n",
      "s: [-1.025238382712062, -1.9911861852806507, -2.308707158324409]\n",
      "s: [-1.1358732458292877, -1.7127569410866732, -1.7951736236016154]\n",
      "s: [-1.4642520296777035, -1.6006349956377548, -1.3169143539506711]\n",
      "s: [-1.881676732459534, -1.4023807033109943, -1.1996749826227207]\n",
      "s: [-2.2842262490879293, -1.4197304055231996, -0.993759180987339]\n",
      "s: [-3.02421467768868, -1.4691981056633425, -0.6548290420127061]\n",
      "s: [-3.6256115739031305, -1.6756537759532941, -0.8162352168022673]\n",
      "s: [-4.101375463181066, -1.8355914633908101, -0.9961939263866852]\n",
      "s: [-4.6595499004498615, -1.72670034835346, -1.238906379773965]\n",
      "s: [-5.24510136662377, -1.7937643232066316, -1.528626304893547]\n",
      "s: [-5.44997551554331, -2.0652327848826797, -1.9023789232781667]\n",
      "s: [-5.956163311790243, -2.918220409213802, -2.1616161733539747]\n",
      "s: [-6.225418473589521, -3.3483328128353396, -2.23442958050389]\n",
      "s: [-6.398247275556343, -3.3910349137361457, -2.6532188721004175]\n",
      "s: [-6.332669218839667, -3.9810537384427445, -3.09677080464151]\n",
      "s: [-6.510735451745611, -4.459519089525203, -3.325233489774205]\n",
      "s: [-6.748843366227001, -4.863190041150072, -3.361492138305158]\n",
      "s: [-7.216834709883106, -5.150469971214326, -3.149003429141513]\n",
      "s: [-7.666367375257767, -5.721785846692052, -3.085325539534001]\n",
      "s: [-7.984410301285543, -6.2756805777614755, -3.1171695374465296]\n",
      "s: [-7.919508323142564, -6.636645126654498, -2.971014042997698]\n",
      "s: [-7.6520015300611615, -6.618595566193607, -3.13153864096871]\n",
      "s: [-7.1619048858262655, -6.373976308150347, -3.0559404430602575]\n",
      "s: [-6.715137408402914, -6.075583515830045, -2.968519058554203]\n",
      "s: [-6.581727109510692, -5.662692563945447, -3.327271280092795]\n",
      "s: [-6.370829053170496, -5.438051944153962, -3.539623807606879]\n",
      "s: [-6.52827280918645, -5.145395175167368, -3.694590086054008]\n",
      "s: [-6.397606135272325, -5.268525569569172, -4.028205943816655]\n",
      "s: [-6.373813899014327, -5.448884039762339, -4.591930907211252]\n",
      "s: [-6.421120221848993, -5.537741120610607, -4.82006446751033]\n",
      "s: [-6.442154679216686, -5.482401880889542, -5.207008781146013]\n",
      "Q: [[ 0.07882588 -0.27673692 -0.18305655]\n",
      " [-0.27673692  1.1180172   0.8088269 ]\n",
      " [-0.18305655  0.8088269   0.61486447]]\n",
      "R: [[ 1.1726999  -0.3190127   0.35826483]\n",
      " [-0.3190127   1.4309678  -0.23884597]\n",
      " [ 0.35826483 -0.23884597  1.1415911 ]]\n",
      "A: [[ 0.12813115 -0.22485042  0.2912929 ]\n",
      " [ 0.6761005   0.5401983  -0.42174792]\n",
      " [ 0.28775573 -0.82797647 -0.27695513]]\n",
      "B: [[-0.9092121  -0.6288338   0.9885161 ]\n",
      " [ 0.09317827  0.4323368  -0.3265841 ]\n",
      " [-0.97310925 -0.50018215 -0.8714392 ]]\n",
      "P: [[ 0.57691073 -0.19056669 -0.49218327]\n",
      " [-0.19056673  1.2116978   0.79108787]\n",
      " [-0.49218336  0.79108787  0.8489613 ]]\n",
      "\tLast Episode Reward: -4606\n",
      "********** Iteration 2 ************\n",
      "s: [-1.4400767355334403, -0.5607323037320713, 0.7365014550699298]\n",
      "s: [-1.661313881838038, -0.3049735689401504, -0.8737409696511715]\n",
      "s: [-1.656857952962755, -0.36381684743286913, -1.3773824986201122]\n",
      "s: [-1.5613084318953863, -0.3006194996360019, -1.5840359656637348]\n",
      "s: [-1.1938649584730763, -0.3667232694938489, -1.745495288422533]\n",
      "s: [-0.9032837824784552, -0.4953375614829958, -1.5758009486147366]\n",
      "s: [-0.550791606953482, -0.3778978938765385, -1.2580250476851866]\n",
      "s: [0.0999478654599294, -0.39164158237753954, -0.9142355815945413]\n",
      "s: [0.6645509739499535, -0.12287605488809994, -0.33292951733351184]\n",
      "s: [0.8954530734109025, 0.2120258496856643, 0.24321774978073624]\n",
      "s: [1.1631642051833437, 0.8260563573526332, 0.9304861361267561]\n",
      "s: [1.2808990980925605, 1.3680068196184587, 1.3631895628885444]\n",
      "s: [1.5194591179632517, 2.0621278934895395, 1.6976890363728983]\n",
      "s: [1.6489353415617798, 2.844861604486458, 1.940287531779549]\n",
      "s: [1.8096000747043455, 3.737397755720715, 2.108031908401342]\n",
      "s: [2.230801563221115, 4.8859740123241195, 2.08523044889925]\n",
      "s: [2.878006452987346, 6.184822733249465, 2.491467318301372]\n",
      "s: [3.955815671913318, 7.161143574018267, 3.3520651306289055]\n",
      "s: [5.57800971903146, 8.473522768275071, 4.21766408013033]\n",
      "s: [7.603032635917168, 9.824864110010875, 5.133312113312315]\n",
      "s: [10.109556464535917, 11.48101213067597, 6.463275569027006]\n",
      "s: [13.146807066206598, 13.91904785510209, 7.792787106646301]\n",
      "s: [17.316393687599728, 17.062158405381368, 9.452059273777964]\n",
      "s: [22.58027181112658, 21.02129381463984, 12.007951624995869]\n",
      "s: [29.1722493839306, 25.839970960200034, 15.778941879590814]\n",
      "s: [37.327029692956465, 32.3326922124097, 20.392968376410526]\n",
      "s: [47.36539164598204, 41.18180558891092, 26.3447282682519]\n",
      "s: [59.96301838091685, 52.408796577775576, 33.59153435120362]\n",
      "s: [75.65555016759365, 66.29149980758135, 43.25259939380385]\n",
      "s: [95.39949365678545, 83.63822135894938, 54.913856934353305]\n",
      "s: [120.01384365201952, 105.61444575796236, 68.95249373031903]\n",
      "s: [150.69000632776329, 133.1570435626475, 86.3701105985888]\n",
      "s: [189.10713202108514, 167.63990496064451, 108.41424545307132]\n",
      "s: [237.54234780686645, 210.72826647922503, 135.7404155292267]\n",
      "s: [298.64529522342025, 265.0162861334291, 170.1708628009128]\n",
      "s: [375.75296007632073, 333.2715506931047, 213.36452904232902]\n",
      "s: [472.56230359313986, 419.42611230375945, 268.086647901983]\n",
      "s: [594.6574501494356, 527.6784869818348, 337.4107602092889]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s: [748.2304737240374, 664.0911355682322, 424.6190063069393]\n",
      "s: [941.6204359964077, 835.9054905919298, 534.5224402558598]\n",
      "s: [1185.0241789256315, 1052.0661010851668, 672.6333056234082]\n",
      "s: [1491.17801477, 1323.9241887608962, 846.5042242751567]\n",
      "s: [1876.6530575245408, 1666.7167551403763, 1065.579553916219]\n",
      "s: [2361.9891735503115, 2098.575145102949, 1341.2982804192027]\n",
      "s: [2973.1322667463774, 2642.022416683717, 1688.243920121122]\n",
      "s: [3742.33087361655, 3325.5272437257872, 2124.9643151490973]\n",
      "s: [4710.565309590571, 4185.865482451922, 2674.597161908154]\n",
      "s: [5929.21605471849, 5268.781811999206, 3366.7159739084664]\n",
      "s: [7463.496497544172, 6632.022039138687, 4237.723545473102]\n",
      "s: [9394.48588321365, 8347.741745494075, 5333.863901014055]\n",
      "s: [11824.938329068811, 10507.492760491732, 6714.1216760917005]\n",
      "s: [14884.093472034465, 13226.355514550527, 8450.920575458316]\n",
      "s: [18734.812053951126, 16648.811122508825, 10637.304138137482]\n",
      "s: [23581.983933957967, 20956.653653907102, 13389.32193578711]\n",
      "s: [29683.724410927272, 26378.577099773524, 16853.348242253094]\n",
      "s: [37364.49066029805, 33203.487768517385, 21213.401208052648]\n",
      "s: [47032.60227546751, 41794.5797576694, 26701.874041626816]\n",
      "s: [59202.47361007904, 52608.192762331615, 33610.71821004409]\n",
      "s: [74521.22284031312, 66219.6565524046, 42307.21437964157]\n",
      "s: [93803.76801214485, 83353.45121893499, 53253.7198896849]\n",
      "s: [118075.33451868764, 104920.82532338586, 67032.60711585746]\n",
      "s: [148626.7208632339, 132068.9653660632, 84376.67591055733]\n",
      "s: [187083.29277003152, 166241.31881932108, 106208.95708847526]\n",
      "s: [235490.23075384472, 209255.86998253746, 133689.65607801118]\n",
      "s: [296422.0507348879, 263399.95924823417, 168280.7274495096]\n",
      "s: [373119.8140477886, 331553.6035137101, 211822.3449910101]\n",
      "s: [469662.8221143669, 417341.5578069937, 266630.1911495086]\n",
      "s: [591186.0621440716, 525326.5248713973, 335619.3038573595]\n",
      "s: [744152.9020243043, 661252.6031672421, 422459.2403741579]\n",
      "s: [936699.2163734345, 832348.3674302421, 531768.7672193052]\n",
      "s: [1179066.0309804291, 1047714.7392538965, 669361.4575024621]\n",
      "s: [1484143.9850957028, 1318806.077898093, 842555.8819036391]\n",
      "s: [1868159.171644306, 1660040.8504785392, 1060563.765749017]\n",
      "s: [2351536.7873118185, 2089569.0255742916, 1334980.036688238]\n",
      "s: [2959986.0204958185, 2630235.8108851165, 1680400.3977564499]\n",
      "s: [3725868.930339607, 3310797.548313722, 2115196.7323402655]\n",
      "s: [4689920.310453495, 4167451.448376462, 2662494.2824115776]\n",
      "s: [5903415.358319612, 5245760.521751845, 3351402.7414712645]\n",
      "s: [7430896.405460089, 6603077.327564855, 4218563.180955552]\n",
      "s: [9353606.678141385, 8311593.590054646, 5310097.149454869]\n",
      "s: [11773809.43558, 10462180.42465648, 6684061.033942433]\n",
      "s: [14820228.367462434, 13169221.788154386, 8413531.297638185]\n",
      "s: [18654894.607811637, 16576697.822740616, 10590494.48226718]\n",
      "s: [23481763.128812604, 20865842.399209723, 13330736.83020576]\n",
      "s: [29557562.348226372, 26264783.832897022, 16780004.63645932]\n",
      "s: [37205446.94953003, 33060676.747373432, 21121754.24961619]\n",
      "s: [46832186.417795956, 41614976.09556407, 26586912.40962221]\n",
      "s: [58949801.181273505, 52382661.68432193, 33466154.77778974]\n",
      "s: [74202792.7216774, 65936436.90267061, 42125369.40459426]\n",
      "s: [93402427.3711127, 82997189.35043459, 53025115.297994114]\n",
      "s: [117569879.23355827, 104472333.56146684, 66745119.42384831]\n",
      "s: [147990548.81385356, 131504073.24116614, 84015117.38226023]\n",
      "s: [186282427.34143534, 165530152.63868397, 105753641.89947525]\n",
      "s: [234482155.76352072, 208360324.24938452, 133116920.14738606]\n",
      "s: [295153342.83925635, 262272608.74912128, 167560316.81897718]\n",
      "s: [371522923.0574396, 330134451.1433471, 210915782.2794926]\n",
      "s: [467652781.71455747, 415555233.3578323, 265489273.1260743]\n",
      "s: [588655801.3115593, 523078253.0737538, 334183407.2107517]\n",
      "s: [740967806.9033154, 658422363.2515781, 420651857.6241007]\n",
      "s: [932689844.727661, 828786146.4644194, 529493605.615556]\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Got info = 2 for batch index 0, expected info = 0. Debug_info = heevd\n\t [[Node: model/Q/SelfAdjointEigV2 = SelfAdjointEigV2[T=DT_FLOAT, compute_v=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](model/MatMul_1)]]\n\t [[Node: model/Mean/_127 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_540_model/Mean\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op 'model/Q/SelfAdjointEigV2', defined at:\n  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/james/Dropbox/stanford/research/current/koopman-lqr/klqr_env/lib/python3.5/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/james/Dropbox/stanford/research/current/koopman-lqr/klqr_env/lib/python3.5/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/james/Dropbox/stanford/research/current/koopman-lqr/klqr_env/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/home/james/Dropbox/stanford/research/current/koopman-lqr/klqr_env/lib/python3.5/site-packages/tornado/platform/asyncio.py\", line 127, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 345, in run_forever\n    self._run_once()\n  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 1312, in _run_once\n    handle._run()\n  File \"/usr/lib/python3.5/asyncio/events.py\", line 125, in _run\n    self._callback(*self._args)\n  File \"/home/james/Dropbox/stanford/research/current/koopman-lqr/klqr_env/lib/python3.5/site-packages/tornado/platform/asyncio.py\", line 117, in _handle_events\n    handler_func(fileobj, events)\n  File \"/home/james/Dropbox/stanford/research/current/koopman-lqr/klqr_env/lib/python3.5/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/james/Dropbox/stanford/research/current/koopman-lqr/klqr_env/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/home/james/Dropbox/stanford/research/current/koopman-lqr/klqr_env/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/james/Dropbox/stanford/research/current/koopman-lqr/klqr_env/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/james/Dropbox/stanford/research/current/koopman-lqr/klqr_env/lib/python3.5/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/james/Dropbox/stanford/research/current/koopman-lqr/klqr_env/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/james/Dropbox/stanford/research/current/koopman-lqr/klqr_env/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/james/Dropbox/stanford/research/current/koopman-lqr/klqr_env/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/james/Dropbox/stanford/research/current/koopman-lqr/klqr_env/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/james/Dropbox/stanford/research/current/koopman-lqr/klqr_env/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/james/Dropbox/stanford/research/current/koopman-lqr/klqr_env/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/james/Dropbox/stanford/research/current/koopman-lqr/klqr_env/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/james/Dropbox/stanford/research/current/koopman-lqr/klqr_env/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/james/Dropbox/stanford/research/current/koopman-lqr/klqr_env/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-13-298b034b9982>\", line 3, in <module>\n    agent.build_model()\n  File \"<ipython-input-10-c1d1074fa2cf>\", line 138, in build_model\n    summarize_matrix('Q', self.Q)\n  File \"<ipython-input-10-c1d1074fa2cf>\", line 16, in summarize_matrix\n    eigvals, _ = tf.linalg.eigh(matrix)\n  File \"/home/james/Dropbox/stanford/research/current/koopman-lqr/klqr_env/lib/python3.5/site-packages/tensorflow/python/ops/linalg_ops.py\", line 348, in self_adjoint_eig\n    e, v = gen_linalg_ops.self_adjoint_eig_v2(tensor, compute_v=True, name=name)\n  File \"/home/james/Dropbox/stanford/research/current/koopman-lqr/klqr_env/lib/python3.5/site-packages/tensorflow/python/ops/gen_linalg_ops.py\", line 1645, in self_adjoint_eig_v2\n    \"SelfAdjointEigV2\", input=input, compute_v=compute_v, name=name)\n  File \"/home/james/Dropbox/stanford/research/current/koopman-lqr/klqr_env/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/james/Dropbox/stanford/research/current/koopman-lqr/klqr_env/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 3392, in create_op\n    op_def=op_def)\n  File \"/home/james/Dropbox/stanford/research/current/koopman-lqr/klqr_env/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1718, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): Got info = 2 for batch index 0, expected info = 0. Debug_info = heevd\n\t [[Node: model/Q/SelfAdjointEigV2 = SelfAdjointEigV2[T=DT_FLOAT, compute_v=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](model/MatMul_1)]]\n\t [[Node: model/Mean/_127 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_540_model/Mean\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/Dropbox/stanford/research/current/koopman-lqr/klqr_env/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox/stanford/research/current/koopman-lqr/klqr_env/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox/stanford/research/current/koopman-lqr/klqr_env/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Got info = 2 for batch index 0, expected info = 0. Debug_info = heevd\n\t [[Node: model/Q/SelfAdjointEigV2 = SelfAdjointEigV2[T=DT_FLOAT, compute_v=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](model/MatMul_1)]]\n\t [[Node: model/Mean/_127 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_540_model/Mean\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-298b034b9982>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0magent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mklqr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrain_agent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_timesteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-11-8b1a130bfabf>\u001b[0m in \u001b[0;36mtrain_agent\u001b[0;34m(agent, env, max_timesteps, max_episodes, max_iters, max_seconds, n_transitions_between_updates, n_optim_steps_per_update, n_iters_per_p_update)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;31m# optimize the model from collected data:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_optim_steps_per_update\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m             \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0miters_so_far\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mn_iters_per_p_update\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-c1d1074fa2cf>\u001b[0m in \u001b[0;36mupdate_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxp_\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnext_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ma_\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0mactions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mr_\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0mrewards\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m         })\n\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox/stanford/research/current/koopman-lqr/klqr_env/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox/stanford/research/current/koopman-lqr/klqr_env/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox/stanford/research/current/koopman-lqr/klqr_env/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox/stanford/research/current/koopman-lqr/klqr_env/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1334\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1335\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1337\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Got info = 2 for batch index 0, expected info = 0. Debug_info = heevd\n\t [[Node: model/Q/SelfAdjointEigV2 = SelfAdjointEigV2[T=DT_FLOAT, compute_v=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](model/MatMul_1)]]\n\t [[Node: model/Mean/_127 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_540_model/Mean\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op 'model/Q/SelfAdjointEigV2', defined at:\n  File \"/usr/lib/python3.5/runpy.py\", line 184, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/james/Dropbox/stanford/research/current/koopman-lqr/klqr_env/lib/python3.5/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/james/Dropbox/stanford/research/current/koopman-lqr/klqr_env/lib/python3.5/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/james/Dropbox/stanford/research/current/koopman-lqr/klqr_env/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/home/james/Dropbox/stanford/research/current/koopman-lqr/klqr_env/lib/python3.5/site-packages/tornado/platform/asyncio.py\", line 127, in start\n    self.asyncio_loop.run_forever()\n  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 345, in run_forever\n    self._run_once()\n  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 1312, in _run_once\n    handle._run()\n  File \"/usr/lib/python3.5/asyncio/events.py\", line 125, in _run\n    self._callback(*self._args)\n  File \"/home/james/Dropbox/stanford/research/current/koopman-lqr/klqr_env/lib/python3.5/site-packages/tornado/platform/asyncio.py\", line 117, in _handle_events\n    handler_func(fileobj, events)\n  File \"/home/james/Dropbox/stanford/research/current/koopman-lqr/klqr_env/lib/python3.5/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/james/Dropbox/stanford/research/current/koopman-lqr/klqr_env/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/home/james/Dropbox/stanford/research/current/koopman-lqr/klqr_env/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/james/Dropbox/stanford/research/current/koopman-lqr/klqr_env/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/james/Dropbox/stanford/research/current/koopman-lqr/klqr_env/lib/python3.5/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/james/Dropbox/stanford/research/current/koopman-lqr/klqr_env/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/james/Dropbox/stanford/research/current/koopman-lqr/klqr_env/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/james/Dropbox/stanford/research/current/koopman-lqr/klqr_env/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/james/Dropbox/stanford/research/current/koopman-lqr/klqr_env/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/james/Dropbox/stanford/research/current/koopman-lqr/klqr_env/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/james/Dropbox/stanford/research/current/koopman-lqr/klqr_env/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/james/Dropbox/stanford/research/current/koopman-lqr/klqr_env/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/james/Dropbox/stanford/research/current/koopman-lqr/klqr_env/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/james/Dropbox/stanford/research/current/koopman-lqr/klqr_env/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-13-298b034b9982>\", line 3, in <module>\n    agent.build_model()\n  File \"<ipython-input-10-c1d1074fa2cf>\", line 138, in build_model\n    summarize_matrix('Q', self.Q)\n  File \"<ipython-input-10-c1d1074fa2cf>\", line 16, in summarize_matrix\n    eigvals, _ = tf.linalg.eigh(matrix)\n  File \"/home/james/Dropbox/stanford/research/current/koopman-lqr/klqr_env/lib/python3.5/site-packages/tensorflow/python/ops/linalg_ops.py\", line 348, in self_adjoint_eig\n    e, v = gen_linalg_ops.self_adjoint_eig_v2(tensor, compute_v=True, name=name)\n  File \"/home/james/Dropbox/stanford/research/current/koopman-lqr/klqr_env/lib/python3.5/site-packages/tensorflow/python/ops/gen_linalg_ops.py\", line 1645, in self_adjoint_eig_v2\n    \"SelfAdjointEigV2\", input=input, compute_v=compute_v, name=name)\n  File \"/home/james/Dropbox/stanford/research/current/koopman-lqr/klqr_env/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/james/Dropbox/stanford/research/current/koopman-lqr/klqr_env/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 3392, in create_op\n    op_def=op_def)\n  File \"/home/james/Dropbox/stanford/research/current/koopman-lqr/klqr_env/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1718, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): Got info = 2 for batch index 0, expected info = 0. Debug_info = heevd\n\t [[Node: model/Q/SelfAdjointEigV2 = SelfAdjointEigV2[T=DT_FLOAT, compute_v=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](model/MatMul_1)]]\n\t [[Node: model/Mean/_127 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_540_model/Mean\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('LQ-v0')\n",
    "agent = klqr(config,sess)\n",
    "agent.build_model()\n",
    "train_agent(agent,env,max_timesteps=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
